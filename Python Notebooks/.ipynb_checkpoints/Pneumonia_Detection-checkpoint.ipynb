{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02e633a8",
   "metadata": {},
   "source": [
    "\n",
    "# Pneumonia Detection using Deep Learning (Chest X-Ray)\n",
    "\n",
    "**Disclaimer:** This notebook is for **research and educational purposes only**.  \n",
    "It is **not approved for clinical use**. Do not use the models trained here for live patient care without rigorous validation and regulatory approval.\n",
    "\n",
    "We will use the **Kaggle Chest X-Ray Pneumonia dataset**:\n",
    "- [Kaggle Dataset Link](https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76be82a1",
   "metadata": {},
   "source": [
    "\n",
    "## Dataset Source\n",
    "\n",
    "The dataset consists of chest X-ray images from pediatric patients:  \n",
    "- **NORMAL** (healthy lungs)  \n",
    "- **PNEUMONIA** (bacterial or viral infection)  \n",
    "\n",
    "Dataset structure after extraction:\n",
    "```\n",
    "chest_xray/\n",
    "    train/\n",
    "        PNEUMONIA/\n",
    "        NORMAL/\n",
    "    val/\n",
    "        PNEUMONIA/\n",
    "        NORMAL/\n",
    "    test/\n",
    "        PNEUMONIA/\n",
    "        NORMAL/\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c78de6c",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a75059",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "import joblib\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cee665",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e535ddf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Change this path after downloading and unzipping the dataset from Kaggle\n",
    "DATASET_PATH = Path(\"chest_xray\")\n",
    "\n",
    "train_dir = DATASET_PATH / \"train\"\n",
    "val_dir = DATASET_PATH / \"val\"\n",
    "test_dir = DATASET_PATH / \"test\"\n",
    "\n",
    "print(\"Train folders:\", os.listdir(train_dir))\n",
    "print(\"Val folders:\", os.listdir(val_dir))\n",
    "print(\"Test folders:\", os.listdir(test_dir))\n",
    "\n",
    "# Count images per class\n",
    "for split in [train_dir, val_dir, test_dir]:\n",
    "    print(f\"\\nCounts in {split.name}:\")\n",
    "    for cls in os.listdir(split):\n",
    "        n_images = len(os.listdir(split / cls))\n",
    "        print(f\"  {cls}: {n_images}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37df14f",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fed51e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Show sample images\n",
    "fig, axes = plt.subplots(1, 4, figsize=(12,4))\n",
    "for i, label in enumerate(['NORMAL', 'PNEUMONIA']):\n",
    "    img_path = random.choice(list((train_dir/label).glob(\"*.jpeg\")))\n",
    "    img = image.load_img(img_path, target_size=(150,150))\n",
    "    axes[i*2].imshow(img, cmap='gray')\n",
    "    axes[i*2].axis('off')\n",
    "    axes[i*2].set_title(label)\n",
    "plt.show()\n",
    "\n",
    "# Class distribution plot\n",
    "counts = {cls: len(os.listdir(train_dir/cls)) for cls in os.listdir(train_dir)}\n",
    "sns.barplot(x=list(counts.keys()), y=list(counts.values()))\n",
    "plt.title(\"Class distribution in Training set\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30219cd",
   "metadata": {},
   "source": [
    "### Data Preprocessing & Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171c96e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMG_SIZE = (224,224)\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=10,\n",
    "                                   width_shift_range=0.05,\n",
    "                                   height_shift_range=0.05,\n",
    "                                   shear_range=0.05,\n",
    "                                   zoom_range=0.1,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(train_dir, target_size=IMG_SIZE,\n",
    "                                              batch_size=BATCH_SIZE, class_mode='categorical')\n",
    "val_gen = val_datagen.flow_from_directory(val_dir, target_size=IMG_SIZE,\n",
    "                                          batch_size=BATCH_SIZE, class_mode='categorical')\n",
    "test_gen = val_datagen.flow_from_directory(test_dir, target_size=IMG_SIZE,\n",
    "                                           batch_size=BATCH_SIZE, class_mode='categorical',\n",
    "                                           shuffle=False)\n",
    "\n",
    "class_indices = train_gen.class_indices\n",
    "print(\"Class indices:\", class_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0833c67c",
   "metadata": {},
   "source": [
    "### Building Transfer Learning Model (DenseNet121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8f0eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "for layer in base_model.layers[:-10]:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(base_model.output)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "output = layers.Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = models.Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85834c11",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a25eb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\"best_model.h5\", save_best_only=True, monitor='val_auc', mode='max'),\n",
    "    tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_auc', mode='max', restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_auc', factor=0.5, patience=3, mode='max')\n",
    "]\n",
    "\n",
    "history = model.fit(train_gen, validation_data=val_gen, epochs=10, callbacks=callbacks)\n",
    "\n",
    "# Plot training curves\n",
    "plt.plot(history.history['accuracy'], label='train_acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label='train_loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208b8d65",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f87c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predictions on test set\n",
    "y_pred_probs = model.predict(test_gen)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = test_gen.classes\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=list(class_indices.keys())))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_indices.keys(), yticklabels=class_indices.keys())\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "auc = roc_auc_score(y_true, y_pred_probs[:,1])\n",
    "print(\"Test ROC AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c5ba2c",
   "metadata": {},
   "source": [
    "### Explainability with Grad-CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f3570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(last_conv_layer_name).output, model.output])\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(predictions[0])\n",
    "        class_channel = predictions[:, pred_index]\n",
    "    grads = tape.gradient(class_channel, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    heatmap = tf.maximum(heatmap, 0) / (tf.math.reduce_max(heatmap) + 1e-8)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "# Example usage\n",
    "img_path = list((test_dir/'PNEUMONIA').glob('*.jpeg'))[0]\n",
    "img = image.load_img(img_path, target_size=IMG_SIZE)\n",
    "arr = image.img_to_array(img)/255.0\n",
    "arr = np.expand_dims(arr, axis=0)\n",
    "\n",
    "heatmap = make_gradcam_heatmap(arr, model, 'conv5_block16_concat')\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.imshow(cv2.resize(heatmap, IMG_SIZE), cmap='jet', alpha=0.5)\n",
    "plt.title(\"Grad-CAM\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ff87c5",
   "metadata": {},
   "source": [
    "### Save Model & Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a613a83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save final model\n",
    "model.save(\"output_pneumonia_model.h5\")\n",
    "\n",
    "# Save preprocessing info\n",
    "preprocessor = {\n",
    "    'target_size': IMG_SIZE,\n",
    "    'color_mode': 'rgb',\n",
    "    'class_indices': class_indices\n",
    "}\n",
    "joblib.dump(preprocessor, \"output_preprocessor.pkl\")\n",
    "\n",
    "print(\"Artifacts saved: output_pneumonia_model.h5 and output_preprocessor.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3b0fe8",
   "metadata": {},
   "source": [
    "### Inference Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b64e6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loaded_model = tf.keras.models.load_model(\"output_pneumonia_model.h5\")\n",
    "loaded_preproc = joblib.load(\"output_preprocessor.pkl\")\n",
    "\n",
    "# Test on a random image\n",
    "sample_path = list((test_dir/'NORMAL').glob('*.jpeg'))[0]\n",
    "img = image.load_img(sample_path, target_size=loaded_preproc['target_size'], color_mode=loaded_preproc['color_mode'])\n",
    "arr = image.img_to_array(img)/255.0\n",
    "arr = np.expand_dims(arr, axis=0)\n",
    "\n",
    "pred = loaded_model.predict(arr)\n",
    "prob = float(pred[0,1])\n",
    "label = list(loaded_preproc['class_indices'].keys())[np.argmax(pred)]\n",
    "\n",
    "print(\"Prediction:\", label, \"Probability Pneumonia:\", prob)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
